{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarjakpatel/CMPE_297_Advanced_Deep_Learning/blob/main/Assignment%205/CMPE_297_Assignment_5_part_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmELjQlPiqMV"
      },
      "source": [
        "# CMPE 297 Assignment 5 Part 2: Active learning with lightly.ai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zJ-fav_jN6V"
      },
      "source": [
        "**Active learning for self-supervised learning model**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing lightly"
      ],
      "metadata": {
        "id": "4x3tOQcJhJn3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6lOLWilnB-L",
        "outputId": "1bf63fef-7a84-4619-9585-41cfcbea8a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightly in /usr/local/lib/python3.7/dist-packages (1.2.35)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.15.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from lightly) (0.13.1+cu113)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.24.3)\n",
            "Requirement already satisfied: lightly-utils~=0.0.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (0.0.2)\n",
            "Requirement already satisfied: pytorch-lightning>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.23.0)\n",
            "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.7/dist-packages (from lightly) (2022.9.24)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.7/dist-packages (from lightly) (4.64.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.8.2)\n",
            "Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (2.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (21.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (5.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from lightly-utils~=0.0.0->lightly) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core>=1.0.0->lightly) (6.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (2.9.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (2022.10.0)\n",
            "Requirement already satisfied: lightning-utilities==0.3.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (0.3.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (1.12.1+cu113)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.7/dist-packages (from lightning-utilities==0.3.*->pytorch-lightning>=1.0.4->lightly) (0.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (3.8.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (22.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core>=1.0.0->lightly) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (2.10)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.38.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.8.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (3.2.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->lightning-utilities==0.3.*->pytorch-lightning>=1.0.4->lightly) (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "Gkw1k7_6hTtC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zz0fE9ujoPP2"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "from lightly.data import LightlyDataset\n",
        "from lightly.data.collate import SMoGCollateFunction\n",
        "from lightly.loss.memory_bank import MemoryBankModule\n",
        "from lightly.models.modules.heads import SMoGProjectionHead\n",
        "from lightly.models.modules.heads import SMoGPredictionHead\n",
        "from lightly.models.modules.heads import SMoGPrototypes\n",
        "from lightly.models import utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VYMF0Xm7Caz"
      },
      "source": [
        "Example implementation of the Synchronous Momentum Grouping (SMoG) paper. SMoG follows the framework of contrastive learning but replaces the contrastive unit from instance to group, mimicking clustering-based methods. To achieve this, they propose the momentum grouping scheme which synchronously conducts feature grouping with representation learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ucz9rVXxoZZh"
      },
      "outputs": [],
      "source": [
        "class SMoGModel(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = SMoGProjectionHead(512, 2048, 128)\n",
        "        self.prediction_head = SMoGPredictionHead(128, 2048, 128)\n",
        "\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "\n",
        "        utils.deactivate_requires_grad(self.backbone_momentum)\n",
        "        utils.deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "        self.n_groups = 300\n",
        "        self.smog = SMoGPrototypes(\n",
        "            group_features=torch.rand(self.n_groups, 128), beta=0.99\n",
        "        )\n",
        "\n",
        "    def _cluster_features(self, features: torch.Tensor) -> torch.Tensor:\n",
        "        # clusters the features using sklearn\n",
        "        # (note: faiss is probably more efficient)\n",
        "        features = features.cpu().numpy()\n",
        "        kmeans = KMeans(self.n_groups).fit(features)\n",
        "        clustered = torch.from_numpy(kmeans.cluster_centers_).float()\n",
        "        clustered = torch.nn.functional.normalize(clustered, dim=1)\n",
        "        return clustered\n",
        "\n",
        "    def reset_group_features(self, memory_bank):\n",
        "        # see https://arxiv.org/pdf/2207.06167.pdf Table 7b)\n",
        "        features = memory_bank.bank\n",
        "        group_features = self._cluster_features(features.t())\n",
        "        self.smog.set_group_features(group_features)\n",
        "\n",
        "    def reset_momentum_weights(self):\n",
        "        # see https://arxiv.org/pdf/2207.06167.pdf Table 7b)\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "        utils.deactivate_requires_grad(self.backbone_momentum)\n",
        "        utils.deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x).flatten(start_dim=1)\n",
        "        encoded = self.projection_head(features)\n",
        "        predicted = self.prediction_head(encoded)\n",
        "        return encoded, predicted\n",
        "\n",
        "    def forward_momentum(self, x):\n",
        "        features = self.backbone_momentum(x).flatten(start_dim=1)\n",
        "        encoded = self.projection_head_momentum(features)\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub0p9q4LodvN",
        "outputId": "f6ae24b2-ee1c-4a8a-e820-577448aa69f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "\n",
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = SMoGModel(backbone)\n",
        "\n",
        "# memory bank because we reset the group features every 300 iterations\n",
        "memory_bank_size = 300 * batch_size\n",
        "memory_bank = MemoryBankModule(size=memory_bank_size)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "cifar10 = torchvision.datasets.CIFAR10(\"datasets/cifar10\", download=True)\n",
        "dataset = LightlyDataset.from_torch_dataset(cifar10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2fAgiJTtohpT"
      },
      "outputs": [],
      "source": [
        "collate_fn = SMoGCollateFunction(\n",
        "    crop_sizes=[32, 32],\n",
        "    crop_counts=[1, 1],\n",
        "    gaussian_blur_probs=[0., 0.],\n",
        "    crop_min_scales=[0.2, 0.2],\n",
        "    crop_max_scales=[1.0, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZEQqK77ok49",
        "outputId": "3ed5fd5b-56ee-45a3-afba-29ddb35db100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g2qfLu-5omr4"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.9,\n",
        "    weight_decay=1e-6\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gnS7FrTPopqJ"
      },
      "outputs": [],
      "source": [
        "global_step = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Trainning"
      ],
      "metadata": {
        "id": "UH1R2vWEh-SP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqfyekAkor5A",
        "outputId": "7f004438-6f45-481b-89ad-e2dd5c9f818a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 00, loss: 3.28153\n",
            "epoch: 01, loss: 3.51225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 02, loss: 4.50965\n",
            "epoch: 03, loss: 4.70726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 04, loss: 4.62236\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "\n",
        "        (x0, x1), _, _ = batch\n",
        "\n",
        "        if batch_idx % 2:\n",
        "            # swap batches every second iteration\n",
        "            x1, x0 = x0, x1\n",
        "\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "\n",
        "        if global_step > 0 and global_step % 300 == 0:\n",
        "            # reset group features and weights every 300 iterations\n",
        "            model.reset_group_features(memory_bank=memory_bank)\n",
        "            model.reset_momentum_weights()\n",
        "        else:\n",
        "            # update momentum\n",
        "            utils.update_momentum(model.backbone, model.backbone_momentum, 0.99)\n",
        "            utils.update_momentum(model.projection_head, model.projection_head_momentum, 0.99)\n",
        "\n",
        "        x0_encoded, x0_predicted = model(x0)\n",
        "        x1_encoded = model.forward_momentum(x1)\n",
        "\n",
        "        # update group features and get group assignments\n",
        "        assignments = model.smog.assign_groups(x1_encoded)\n",
        "        group_features = model.smog.get_updated_group_features(x0_encoded)\n",
        "        logits = model.smog(x0_predicted, group_features, temperature=0.1)\n",
        "        model.smog.set_group_features(group_features)\n",
        "\n",
        "        loss = criterion(logits, assignments)\n",
        "\n",
        "        # use memory bank to periodically reset the group features with k-means\n",
        "        memory_bank(x0_encoded, update=True)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        global_step += 1\n",
        "        total_loss += loss.detach()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5YeIjhp60WB"
      },
      "source": [
        "## Reference:\n",
        " \n",
        "*   https://github.com/lightly-ai/lightly\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}